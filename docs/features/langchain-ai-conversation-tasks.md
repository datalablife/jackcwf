# LangChain v1.0 AI Conversation - Tasks & Stories

**Feature**: LangChain v1.0 AI Conversation with Agents and RAG
**Version**: 1.0.0
**Created**: 2025-11-16
**Status**: Ready for Development

---

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£å°†åŠŸèƒ½è§„èŒƒå’Œå®ç°è®¡åˆ’åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„ **Epics â†’ Stories â†’ Tasks**ã€‚

**ä¾èµ–äº**:
- `.specify/memory/constitution.md` (8 ä¸ªæ ¸å¿ƒåŸåˆ™)
- `langchain-ai-conversation-spec.md` (åŠŸèƒ½è§„èŒƒ)
- `langchain-ai-conversation-plan.md` (å®ç°è®¡åˆ’)

---

## ğŸ¯ Epic åˆ†è§£

### Epic 1: åç«¯åŸºç¡€è®¾æ–½
**æŒç»­æ—¶é—´**: Week 1-2 (10 ä¸ªå·¥ä½œæ—¥)
**é¢„ä¼°æ•…äº‹ç‚¹**: 8-13

### Epic 2: Agent å’Œ RAG
**æŒç»­æ—¶é—´**: Week 2-3 (10 ä¸ªå·¥ä½œæ—¥)
**é¢„ä¼°æ•…äº‹ç‚¹**: 13-21

### Epic 3: ä¸­é—´ä»¶å’Œç‰¹æ€§
**æŒç»­æ—¶é—´**: Week 3-4 (10 ä¸ªå·¥ä½œæ—¥)
**é¢„ä¼°æ•…äº‹ç‚¹**: 13-21

### Epic 4: å‰ç«¯å¼€å‘
**æŒç»­æ—¶é—´**: Week 4-5 (10 ä¸ªå·¥ä½œæ—¥)
**é¢„ä¼°æ•…äº‹ç‚¹**: 13-21

### Epic 5: æµ‹è¯•å’Œä¼˜åŒ–
**æŒç»­æ—¶é—´**: Week 5-6 (10 ä¸ªå·¥ä½œæ—¥)
**é¢„ä¼°æ•…äº‹ç‚¹**: 8-13

### Epic 6: éƒ¨ç½²å’Œä¸Šçº¿
**æŒç»­æ—¶é—´**: Week 6-7 (5 ä¸ªå·¥ä½œæ—¥)
**é¢„ä¼°æ•…äº‹ç‚¹**: 3-5

---

## ğŸ“š Story è¯¦ç»†åˆ†è§£

---

# ğŸš€ EPIC 1: åç«¯åŸºç¡€è®¾æ–½ (Week 1-2)

## Story 1.1: æ•°æ®åº“è®¾è®¡å’Œè¿ç§»

**æ•…äº‹ç‚¹**: 5
**ä¼˜å…ˆçº§**: P0 (é˜»å¡)
**åˆ†é…ç»™**: Backend Lead
**æ ‡ç­¾**: database, infrastructure, async

### ç”¨æˆ·æ•…äº‹

```gherkin
As a backend developer
I want to have a properly designed and tested database
So that data is stored reliably with good query performance

Acceptance Criteria:
- [ ] 4 ä¸ªæ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ (conversations, messages, documents, embeddings)
- [ ] æ‰€æœ‰ç´¢å¼•åˆ›å»ºå®Œæˆ (7+ ç´¢å¼•)
- [ ] åˆ†åŒºç­–ç•¥é…ç½®å®Œæˆ (embeddings æŒ‰æœˆåˆ†åŒº)
- [ ] æ•°æ®åº“è¿ç§»è„šæœ¬é€šè¿‡æµ‹è¯•
- [ ] çº¦æŸå’Œå…³ç³»è®¾ç½®æ­£ç¡®
```

### ä»»åŠ¡åˆ†è§£

#### Task 1.1.1: åˆ›å»º conversations è¡¨
**æ•…äº‹ç‚¹**: 1
**å®Œæˆæ ‡å‡†**:
- [ ] è¡¨ç»“æ„åˆ›å»º (id, user_id, title, summary, model, system_prompt, metadata, is_deleted, created_at, updated_at)
- [ ] ä¸»é”®å’Œå¤–é”®çº¦æŸ
- [ ] è½¯åˆ é™¤æœºåˆ¶ (is_deleted)
- [ ] æ—¶é—´æˆ³ç®¡ç† (created_at, updated_at)
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡

```sql
-- ç¤ºä¾‹
CREATE TABLE conversations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id VARCHAR NOT NULL,
    title VARCHAR(255) NOT NULL,
    summary TEXT,
    model VARCHAR(100) DEFAULT 'claude-sonnet-4-5-20250929',
    system_prompt TEXT NOT NULL,
    metadata JSONB DEFAULT '{}',
    is_deleted BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    deleted_at TIMESTAMP,

    CONSTRAINT fk_user_id FOREIGN KEY (user_id) REFERENCES users(id)
);
```

#### Task 1.1.2: åˆ›å»º messages è¡¨
**æ•…äº‹ç‚¹**: 1
**å®Œæˆæ ‡å‡†**:
- [ ] è¡¨ç»“æ„åˆ›å»º (id, conversation_id, role, content, tool_calls, tool_results, tokens_used, metadata, created_at)
- [ ] å¤–é”®çº¦æŸåˆ° conversations
- [ ] è§’è‰²æ£€æŸ¥çº¦æŸ (user, assistant, system)
- [ ] JSON å­—æ®µç”¨äºå·¥å…·è°ƒç”¨/ç»“æœ
- [ ] çº§è”åˆ é™¤é…ç½®

#### Task 1.1.3: åˆ›å»º documents å’Œ embeddings è¡¨
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] documents è¡¨åˆ›å»º (id, user_id, filename, file_type, content, total_chunks, metadata, is_deleted, created_at, updated_at)
- [ ] embeddings è¡¨åˆ›å»º (id, document_id, chunk_text, embedding vector(1536), chunk_index, metadata, created_at, is_deleted)
- [ ] å‘é‡ç±»å‹é…ç½® (pgvector æ‰©å±•)
- [ ] å¤–é”®å…³ç³»
- [ ] çº§è”åˆ é™¤

#### Task 1.1.4: åˆ›å»ºæ‰€æœ‰ç´¢å¼•
**æ•…äº‹ç‚¹**: 1
**å®Œæˆæ ‡å‡†**:
- [ ] conversations ç´¢å¼• (user_created, user_active, title_search)
- [ ] messages ç´¢å¼• (conversation, role, conversation_recent)
- [ ] documents ç´¢å¼• (user_created, user_active)
- [ ] embeddings ç´¢å¼• (HNSW vector index, document, created, document_chunk)
- [ ] ç´¢å¼•æ€§èƒ½éªŒè¯

#### Task 1.1.5: é…ç½®åˆ†åŒºç­–ç•¥
**æ•…äº‹ç‚¹**: 1
**å®Œæˆæ ‡å‡†**:
- [ ] embeddings è¡¨æŒ‰æ—¶é—´åˆ†åŒº (æŒ‰æœˆ)
- [ ] åˆ›å»ºåˆå§‹åˆ†åŒº (å½“å‰æœˆä»½å’Œä¸‹ä¸ªæœˆä»½)
- [ ] è‡ªåŠ¨åˆ†åŒºè„šæœ¬ç¼–å†™ (æ¯æœˆåˆ›å»ºæ–°åˆ†åŒº)
- [ ] åˆ†åŒºæŸ¥è¯¢æ€§èƒ½æµ‹è¯•

---

## Story 1.2: å¼‚æ­¥å­˜å‚¨åº“å®ç°

**æ•…äº‹ç‚¹**: 8
**ä¼˜å…ˆçº§**: P0 (é˜»å¡)
**åˆ†é…ç»™**: Backend Team (2-3 äºº)
**æ ‡ç­¾**: async, repository, database

### ç”¨æˆ·æ•…äº‹

```gherkin
As a backend service
I want to have async-first repository layer
So that I/O operations are non-blocking and performant

Acceptance Criteria:
- [ ] 4 ä¸ªå­˜å‚¨åº“å®ç° (Conversation, Message, Document, Embedding)
- [ ] æ‰€æœ‰æ•°æ®åº“æ“ä½œä½¿ç”¨ async/await
- [ ] asyncpg é©±åŠ¨é…ç½®å®Œæˆ
- [ ] SQLAlchemy async session ç®¡ç†
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ â‰¥ 80%
- [ ] mypy --strict é€šè¿‡
```

### ä»»åŠ¡åˆ†è§£

#### Task 1.2.1: åŸºç¡€å­˜å‚¨åº“æ¡†æ¶
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] BaseRepository æŠ½è±¡ç±»åˆ›å»º
- [ ] AsyncSessionLocal é…ç½®
- [ ] æ•°æ®åº“è¿æ¥æ± é…ç½®
- [ ] äº‹åŠ¡ç®¡ç†å®ç°
- [ ] é”™è¯¯å¤„ç†æ¨¡æ¿

```python
# backend/src/repositories/base_repository.py

from sqlalchemy.ext.asyncio import AsyncSession
from typing import Generic, TypeVar, Optional, List
from abc import ABC, abstractmethod

T = TypeVar('T')

class BaseRepository(ABC, Generic[T]):
    """å¼‚æ­¥å­˜å‚¨åº“åŸºç±»"""

    def __init__(self, session: AsyncSession):
        self.session = session

    async def create(self, obj: T) -> T:
        """åˆ›å»ºå¯¹è±¡"""
        self.session.add(obj)
        await self.session.commit()
        await self.session.refresh(obj)
        return obj

    async def get(self, id: str) -> Optional[T]:
        """æŒ‰ ID è·å–"""
        return await self.session.get(self.model, id)

    async def list(self, skip: int = 0, limit: int = 10) -> List[T]:
        """åˆ—å‡ºå¯¹è±¡"""
        result = await self.session.execute(
            select(self.model).offset(skip).limit(limit)
        )
        return result.scalars().all()

    async def update(self, obj: T) -> T:
        """æ›´æ–°å¯¹è±¡"""
        await self.session.merge(obj)
        await self.session.commit()
        return obj

    async def delete(self, id: str) -> bool:
        """åˆ é™¤å¯¹è±¡"""
        obj = await self.get(id)
        if obj:
            await self.session.delete(obj)
            await self.session.commit()
            return True
        return False
```

#### Task 1.2.2: ConversationRepository å®ç°
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] åˆ›å»ºæ–¹æ³• (user_id, title, system_prompt, model)
- [ ] è·å–æ–¹æ³• (æŒ‰ ID å’Œ user_id)
- [ ] åˆ—è¡¨æ–¹æ³• (æŒ‰ user_id æ’åº)
- [ ] æ›´æ–°æ–¹æ³• (title, summary, system_prompt)
- [ ] è½¯åˆ é™¤æ–¹æ³•
- [ ] å•å…ƒæµ‹è¯• (â‰¥90% è¦†ç›–)

```python
# ç¤ºä¾‹æ–¹æ³•
class ConversationRepository(BaseRepository[ConversationORM]):
    async def get_by_user(self, user_id: str) -> List[ConversationORM]:
        """è·å–ç”¨æˆ·çš„æ‰€æœ‰å¯¹è¯"""
        result = await self.session.execute(
            select(ConversationORM)
            .where(ConversationORM.user_id == user_id)
            .where(ConversationORM.is_deleted == False)
            .order_by(ConversationORM.created_at.desc())
        )
        return result.scalars().all()

    async def soft_delete(self, conversation_id: str) -> bool:
        """è½¯åˆ é™¤å¯¹è¯"""
        conversation = await self.get(conversation_id)
        if conversation:
            conversation.is_deleted = True
            conversation.deleted_at = datetime.utcnow()
            await self.update(conversation)
            return True
        return False
```

#### Task 1.2.3: MessageRepository å®ç°
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] åˆ›å»ºæ–¹æ³• (conversation_id, role, content, tool_calls, tool_results)
- [ ] æŒ‰å¯¹è¯è·å–æ–¹æ³• (å¸¦åˆ†é¡µ)
- [ ] æŒ‰è§’è‰²è¿‡æ»¤æ–¹æ³•
- [ ] æ›´æ–°å·¥å…·ç»“æœæ–¹æ³•
- [ ] å•å…ƒæµ‹è¯• (â‰¥90% è¦†ç›–)

#### Task 1.2.4: DocumentRepository å’Œ EmbeddingRepository å®ç°
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] DocumentRepository (upload, list, get, delete)
- [ ] EmbeddingRepository (insert, search, delete)
- [ ] å‘é‡æœç´¢å®ç° (HNSW, cosine similarity, â‰¤200ms)
- [ ] æ‰¹é‡æ’å…¥ä¼˜åŒ–
- [ ] å•å…ƒæµ‹è¯• (â‰¥90% è¦†ç›–)

```python
# EmbeddingRepository ç¤ºä¾‹

class EmbeddingRepository(BaseRepository[EmbeddingORM]):
    async def search(
        self,
        query_embedding: List[float],
        user_id: str,
        limit: int = 5,
        threshold: float = 0.7
    ) -> List[EmbeddingORM]:
        """
        ä½¿ç”¨ pgvector ç›¸ä¼¼æ€§æœç´¢

        Performance Target: â‰¤ 200ms P99
        """
        import time
        start = time.time()

        # pgvector ä½™å¼¦ç›¸ä¼¼æ€§æœç´¢
        result = await self.session.execute(
            select(EmbeddingORM)
            .join(DocumentORM)
            .where(DocumentORM.user_id == user_id)
            .where(EmbeddingORM.embedding.cosine_distance(query_embedding) < 1 - threshold)
            .where(EmbeddingORM.is_deleted == False)
            .order_by(EmbeddingORM.embedding.cosine_distance(query_embedding))
            .limit(limit)
        )

        embeddings = result.scalars().all()
        elapsed_ms = (time.time() - start) * 1000

        # è®°å½•æ€§èƒ½
        logger.info(f"Vector search completed in {elapsed_ms:.2f}ms")
        assert elapsed_ms <= 200, f"Vector search too slow: {elapsed_ms}ms"

        return embeddings

    async def batch_insert(self, embeddings: List[EmbeddingORM]) -> int:
        """
        æ‰¹é‡æ’å…¥å‘é‡

        Performance Target: â‰¤ 100ms per 1000 vectors
        """
        self.session.add_all(embeddings)
        await self.session.commit()
        return len(embeddings)
```

---

## Story 1.3: API æ¡†æ¶æ­å»º

**æ•…äº‹ç‚¹**: 5
**ä¼˜å…ˆçº§**: P0 (é˜»å¡)
**åˆ†é…ç»™**: Backend Lead
**æ ‡ç­¾**: api, fastapi, framework

### ä»»åŠ¡åˆ†è§£

#### Task 1.3.1: FastAPI åº”ç”¨åˆå§‹åŒ–
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] FastAPI åº”ç”¨åˆ›å»º
- [ ] ç¯å¢ƒå˜é‡åŠ è½½ (.env)
- [ ] CORS é…ç½®
- [ ] é€Ÿç‡é™åˆ¶é…ç½®
- [ ] å…¨å±€å¼‚å¸¸å¤„ç†

#### Task 1.3.2: è·¯ç”±æ³¨å†Œå’Œé¡¹ç›®å¸ƒå±€
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] v1 è·¯ç”±æ³¨å†Œ
- [ ] API è“å›¾åˆ†ç¦»
- [ ] ä¾èµ–æ³¨å…¥è®¾ç½®
- [ ] å¥åº·æ£€æŸ¥ç«¯ç‚¹ (/health)

#### Task 1.3.3: æ–‡æ¡£å’Œ OpenAPI é…ç½®
**æ•…äº‹ç‚¹**: 1
**å®Œæˆæ ‡å‡†**:
- [ ] Swagger UI é…ç½®
- [ ] OpenAPI schema è‡ªåŠ¨ç”Ÿæˆ
- [ ] æ‰€æœ‰ç«¯ç‚¹æ–‡æ¡£

---

# ğŸ¤– EPIC 2: Agent å’Œ RAG (Week 2-3)

## Story 2.1: å‘é‡åŒ–ã€RAG ç®¡é“ å’Œ é•¿å¯¹è¯æ€»ç»“

**æ•…äº‹ç‚¹**: 18 (13 + 5 for Task 2.1.5)
**ä¼˜å…ˆçº§**: P0 (é˜»å¡)
**åˆ†é…ç»™**: AI/ML Team + Backend Team
**æ ‡ç­¾**: ai, rag, embedding, langchain, conversation-management

### ç”¨æˆ·æ•…äº‹

```gherkin
As a user
I want to upload documents and get AI responses based on them
So that I can have conversations grounded in my specific knowledge

Acceptance Criteria:
- [ ] æ–‡æ¡£åˆ†å—æˆåŠŸ (1000 tokens, 200 token overlap)
- [ ] å‘é‡åŒ–å®Œæˆ (1536-dim, OpenAI Ada)
- [ ] pgvector å­˜å‚¨æˆåŠŸ
- [ ] ç›¸ä¼¼æ€§æœç´¢å·¥ä½œ (â‰¤200ms P99)
- [ ] RAG é›†æˆåˆ° Agent
- [ ] å•å…ƒæµ‹è¯•è¦†ç›– â‰¥80%
```

### ä»»åŠ¡åˆ†è§£

#### Task 2.1.1: æ–‡æ¡£åˆ†å—ç®¡é“
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] æ–‡æ¡£åŠ è½½å™¨ (PDF, TXT, MD)
- [ ] æ–‡æœ¬åˆ†å— (1000 tokens, 200 overlap)
- [ ] å…ƒæ•°æ®æå– (é¡µç , ç« èŠ‚, ä½ç½®)
- [ ] åˆ†å—éªŒè¯å’Œé”™è¯¯å¤„ç†
- [ ] å•å…ƒæµ‹è¯•

```python
# backend/src/services/document_service.py

import fitz  # PDF
from typing import List, Tuple

class DocumentChunker:
    """æ–‡æ¡£åˆ†å—æœåŠ¡"""

    def __init__(self, chunk_size: int = 1000, overlap: int = 200):
        self.chunk_size = chunk_size
        self.overlap = overlap

    async def chunk_document(
        self,
        content: str,
        metadata: dict
    ) -> List[Tuple[str, dict]]:
        """
        å°†æ–‡æ¡£åˆ†å—

        Args:
            content: æ–‡æ¡£å†…å®¹
            metadata: å…ƒæ•°æ® (é¡µç ã€æ¥æºç­‰)

        Returns:
            [(chunk_text, chunk_metadata), ...]
        """
        chunks = []
        tokens = content.split()  # ç®€åŒ–ï¼Œå®é™…ç”¨ tiktoken

        chunk_idx = 0
        for i in range(0, len(tokens), self.chunk_size - self.overlap):
            chunk_tokens = tokens[i:i + self.chunk_size]
            chunk_text = ' '.join(chunk_tokens)

            chunk_metadata = {
                **metadata,
                'chunk_index': chunk_idx,
                'chunk_start': i,
                'chunk_end': min(i + self.chunk_size, len(tokens))
            }

            chunks.append((chunk_text, chunk_metadata))
            chunk_idx += 1

        return chunks
```

#### Task 2.1.2: OpenAI å‘é‡åŒ–é›†æˆ
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] OpenAI å®¢æˆ·ç«¯é›†æˆ
- [ ] text-embedding-3-small æ¨¡å‹ (1536-dim)
- [ ] æ‰¹é‡å‘é‡åŒ–å¤„ç†
- [ ] é”™è¯¯é‡è¯•æœºåˆ¶
- [ ] æˆæœ¬ç›‘æ§

```python
# backend/src/services/embedding_service.py

from openai import AsyncOpenAI

class EmbeddingService:
    """å‘é‡åŒ–æœåŠ¡"""

    def __init__(self, openai_key: str):
        self.client = AsyncOpenAI(api_key=openai_key)

    async def embed_text(self, text: str) -> List[float]:
        """å‘é‡åŒ–å•ä¸ªæ–‡æœ¬"""
        response = await self.client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding

    async def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡å‘é‡åŒ–"""
        response = await self.client.embeddings.create(
            model="text-embedding-3-small",
            input=texts
        )
        return [item.embedding for item in response.data]

    def validate_embedding(self, embedding: List[float]):
        """éªŒè¯å‘é‡ç»´åº¦"""
        assert len(embedding) == 1536, \
            f"Expected 1536-dim, got {len(embedding)}-dim"
```

#### Task 2.1.3: pgvector å­˜å‚¨å’Œæœç´¢
**æ•…äº‹ç‚¹**: 4
**å®Œæˆæ ‡å‡†**:
- [ ] pgvector æ‰©å±•å·²å®‰è£…
- [ ] å‘é‡è§„èŒƒåŒ– (L2)
- [ ] HNSW ç´¢å¼•åˆ›å»º
- [ ] ç›¸ä¼¼æ€§æœç´¢å®ç° (cosine)
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯• (â‰¤200ms P99)
- [ ] ç¼“å­˜ç­–ç•¥ (Redis)

```python
# backend/src/repositories/embedding_repository.py

from sqlalchemy import func
from pgvector.sqlalchemy import Vector

class EmbeddingRepository:
    async def store_embedding(
        self,
        document_id: str,
        chunk_text: str,
        embedding: List[float],
        chunk_index: int,
        metadata: dict
    ) -> str:
        """å­˜å‚¨å•ä¸ªå‘é‡"""
        embedding_orm = EmbeddingORM(
            document_id=document_id,
            chunk_text=chunk_text,
            embedding=embedding,  # pgvector è‡ªåŠ¨å¤„ç†
            chunk_index=chunk_index,
            metadata=metadata
        )
        return await self.create(embedding_orm)

    async def search(
        self,
        query_embedding: List[float],
        user_id: str,
        limit: int = 5,
        threshold: float = 0.7
    ) -> List[dict]:
        """
        ç›¸ä¼¼æ€§æœç´¢

        ä½¿ç”¨ pgvector <-> æ“ä½œç¬¦ (cosine distance)
        æ€§èƒ½: â‰¤ 200ms P99
        """
        import time
        start = time.time()

        # ä½™å¼¦ç›¸ä¼¼æ€§: 1 - (dot_product / (norm_a * norm_b))
        # pgvector: <-> æ“ä½œç¬¦
        result = await self.session.execute(
            select(
                EmbeddingORM.id,
                EmbeddingORM.chunk_text,
                EmbeddingORM.metadata,
                # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
                (1 - (EmbeddingORM.embedding <-> query_embedding)).label('score')
            )
            .join(DocumentORM)
            .where(DocumentORM.user_id == user_id)
            .where((1 - (EmbeddingORM.embedding <-> query_embedding)) >= threshold)
            .where(EmbeddingORM.is_deleted == False)
            .order_by('score')
            .limit(limit)
        )

        rows = result.all()
        elapsed_ms = (time.time() - start) * 1000

        logger.info(f"Vector search completed: {len(rows)} results in {elapsed_ms:.2f}ms")

        return [
            {
                'id': row[0],
                'text': row[1],
                'metadata': row[2],
                'score': row[3]
            }
            for row in rows
        ]
```

#### Task 2.1.4: æ–‡æ¡£ä¸Šä¼ ç«¯ç‚¹
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] æ–‡ä»¶ä¸Šä¼ å¤„ç† (PDF, TXT, MD)
- [ ] æ–‡æ¡£åˆ†å—å’Œå‘é‡åŒ–
- [ ] å‘é‡æ‰¹é‡å­˜å‚¨
- [ ] è¿›åº¦è·Ÿè¸ª (å¼‚æ­¥å¤„ç†)
- [ ] é”™è¯¯å¤„ç†å’Œæ¢å¤

#### Task 2.1.5: é•¿å¯¹è¯æ€»ç»“å’Œä¸Šä¸‹æ–‡å‹ç¼© (A4 è¡¥æ•‘)
**æ•…äº‹ç‚¹**: 5
**ä¼˜å…ˆçº§**: P1 (é«˜)
**å®Œæˆæ ‡å‡†**:
- [ ] å¯¹è¯é•¿åº¦ç›‘æ§ (>5000 tokens)
- [ ] è‡ªåŠ¨æ€»ç»“è§¦å‘æœºåˆ¶
- [ ] åŸºäºLLMçš„æ€»ç»“ç”Ÿæˆ
- [ ] æ€»ç»“ç¼“å­˜å’Œå­˜å‚¨
- [ ] æ€»ç»“æ³¨å…¥åˆ°ä¸Šä¸‹æ–‡
- [ ] å•å…ƒå’Œé›†æˆæµ‹è¯•

**å®ç°æŒ‡å—**:

```python
# backend/src/services/conversation_summarization_service.py

import tiktoken
from typing import Optional
from datetime import datetime

class ConversationSummarizationService:
    """é•¿å¯¹è¯æ€»ç»“æœåŠ¡ - é˜²æ­¢tokenè†¨èƒ€"""

    def __init__(self, anthropic_client, max_context_tokens: int = 6000):
        self.client = anthropic_client
        self.max_context_tokens = max_context_tokens
        self.tokenizer = tiktoken.encoding_for_model("gpt-3.5-turbo")

    async def check_and_summarize(
        self,
        conversation_id: str,
        messages: List[dict],
        force_summarize: bool = False
    ) -> Optional[dict]:
        """
        æ£€æŸ¥å¯¹è¯é•¿åº¦ï¼Œå¿…è¦æ—¶ç”Ÿæˆæ€»ç»“

        Args:
            conversation_id: å¯¹è¯ID
            messages: å½“å‰æ¶ˆæ¯åˆ—è¡¨
            force_summarize: å¼ºåˆ¶æ€»ç»“ï¼ˆç”¨äºç‰¹åˆ«é•¿çš„å¯¹è¯ï¼‰

        Returns:
            æ€»ç»“å¯¹è±¡æˆ–Noneï¼ˆæ— éœ€æ€»ç»“ï¼‰
        """
        # è®¡ç®—å½“å‰å¯¹è¯çš„tokenæ•°
        total_tokens = await self._count_tokens(messages)

        # åˆ¤æ–­æ˜¯å¦éœ€è¦æ€»ç»“
        if total_tokens > self.max_context_tokens or force_summarize:
            return await self._generate_summary(
                conversation_id=conversation_id,
                messages=messages,
                token_count=total_tokens
            )

        return None

    async def _count_tokens(self, messages: List[dict]) -> int:
        """è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„tokenæ•°"""
        total = 0
        for msg in messages:
            # æ·»åŠ æ¶ˆæ¯å¤´å¼€é”€
            total += 4
            # æ·»åŠ å†…å®¹token
            content = msg.get("content", "")
            total += len(self.tokenizer.encode(content))
        return total

    async def _generate_summary(
        self,
        conversation_id: str,
        messages: List[dict],
        token_count: int
    ) -> dict:
        """ç”Ÿæˆå¯¹è¯æ€»ç»“"""

        # æ„å»ºæ€»ç»“æç¤º
        summary_prompt = self._build_summary_prompt(messages)

        # è°ƒç”¨Claude APIç”Ÿæˆæ€»ç»“
        response = await self.client.messages.create(
            model="claude-sonnet-4-5-20250929",
            max_tokens=500,
            system="You are a conversation summarizer. Create concise, factual summaries of conversations.",
            messages=[{
                "role": "user",
                "content": summary_prompt
            }]
        )

        summary_text = response.content[0].text

        # å­˜å‚¨æ€»ç»“åˆ°æ•°æ®åº“
        summary_record = {
            "conversation_id": conversation_id,
            "summary": summary_text,
            "original_message_count": len(messages),
            "original_token_count": token_count,
            "summarized_message_count": await self._count_summarized_messages(messages),
            "created_at": datetime.utcnow(),
            "is_active": True
        }

        # ä¿å­˜åˆ°æ•°æ®åº“
        await self.summary_repository.create(summary_record)

        # è®°å½•äº‹ä»¶
        await logger.ainfo(
            "conversation_summarized",
            conversation_id=conversation_id,
            original_tokens=token_count,
            summary_length=len(summary_text)
        )

        return summary_record

    def _build_summary_prompt(self, messages: List[dict]) -> str:
        """æ„å»ºæ€»ç»“æç¤º"""
        # åªåŒ…å«æœ€è¿‘çš„æ¶ˆæ¯æ¥é™ä½æˆæœ¬
        recent_messages = messages[-20:]

        prompt = "Summarize this conversation:\n\n"
        for msg in recent_messages:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            prompt += f"{role}: {content}\n"

        prompt += """
Provide a concise summary covering:
1. Main topics discussed
2. Key decisions or conclusions
3. Important context for future messages
Keep the summary under 200 tokens.
"""
        return prompt

    async def _count_summarized_messages(self, messages: List[dict]) -> int:
        """è®¡ç®—éœ€è¦è¢«æ€»ç»“çš„æ¶ˆæ¯æ•°ï¼ˆä¿ç•™æœ€åå‡ æ¡ï¼‰"""
        # ä¿ç•™æœ€å10æ¡æ¶ˆæ¯ï¼Œå…¶ä½™çš„å°†è¢«æ€»ç»“
        return max(0, len(messages) - 10)

    async def inject_summary_into_context(
        self,
        conversation_id: str,
        recent_messages: List[dict]
    ) -> List[dict]:
        """
        å°†æ€»ç»“æ³¨å…¥åˆ°ä¸Šä¸‹æ–‡ä¸­

        è¿”å›: [æ€»ç»“æ¶ˆæ¯, ...æœ€è¿‘æ¶ˆæ¯]
        """
        # è·å–æœ€æ–°çš„æ€»ç»“
        summary = await self.summary_repository.get_latest(conversation_id)

        if not summary or not summary["is_active"]:
            return recent_messages

        # æ„å»ºæ€»ç»“æ¶ˆæ¯
        summary_message = {
            "role": "system",
            "content": f"Previous conversation summary:\n{summary['summary']}"
        }

        # è¿”å›æ€»ç»“ + æœ€è¿‘æ¶ˆæ¯
        return [summary_message] + recent_messages

# ç›‘æ§å’Œå‘Šè­¦
async def monitor_conversation_length(conversation_id: str, message_count: int):
    """ç›‘æ§å¯¹è¯é•¿åº¦ï¼Œç”¨äºå‘Šè­¦"""
    if message_count > 100:
        await logger.awarn(
            "conversation_very_long",
            conversation_id=conversation_id,
            message_count=message_count,
            recommendation="consider_summarization"
        )

# æµ‹è¯•
@pytest.mark.asyncio
async def test_long_conversation_summarization():
    """æµ‹è¯•é•¿å¯¹è¯æ€»ç»“"""
    service = ConversationSummarizationService(
        anthropic_client=mock_client,
        max_context_tokens=6000
    )

    # åˆ›å»ºè¶…é•¿å¯¹è¯ï¼ˆ>6000 tokensï¼‰
    long_messages = [
        {"role": "user", "content": "..." * 100},  # å¾ˆå¤štoken
        {"role": "assistant", "content": "..." * 100},
    ] * 20

    # è§¦å‘æ€»ç»“
    summary = await service.check_and_summarize(
        conversation_id="test_conv",
        messages=long_messages
    )

    assert summary is not None
    assert "summary" in summary
    assert summary["original_token_count"] > 6000

@pytest.mark.asyncio
async def test_summary_injection():
    """æµ‹è¯•æ€»ç»“æ³¨å…¥"""
    service = ConversationSummarizationService(mock_client)

    recent_messages = [
        {"role": "user", "content": "latest question"}
    ]

    # æ³¨å…¥æ€»ç»“
    context_with_summary = await service.inject_summary_into_context(
        conversation_id="test_conv",
        recent_messages=recent_messages
    )

    # éªŒè¯æ€»ç»“åœ¨å¼€å¤´
    assert context_with_summary[0]["role"] == "system"
    assert "summary" in context_with_summary[0]["content"].lower()
```

**ç›¸å…³é…ç½®å’Œç›‘æ§**:
```python
# backend/.env
CONVERSATION_SUMMARY_TOKEN_THRESHOLD=6000        # è§¦å‘æ€»ç»“çš„tokené˜ˆå€¼
CONVERSATION_SUMMARY_RETENTION_MESSAGES=10       # ä¿ç•™çš„æœ€è¿‘æ¶ˆæ¯æ•°
CONVERSATION_SUMMARY_ENABLED=true
CONVERSATION_SUMMARY_COST_MONITOR=true          # ç›‘æ§æˆæœ¬

# backend/src/monitoring/alerts.yaml
alerts:
  - name: ConversationTooLong
    condition: message_count > 100
    severity: warning
    action: recommend_summarization
```

---

## Story 2.2: LangChain Agent å®ç°

**æ•…äº‹ç‚¹**: 13
**ä¼˜å…ˆçº§**: P0 (é˜»å¡)
**åˆ†é…ç»™**: AI/ML Team
**æ ‡ç­¾**: ai, langchain, agent, tools

### ç”¨æˆ·æ•…äº‹

```gherkin
As an AI system
I want to create a flexible agent with tools
So that I can handle complex queries with tool usage

Acceptance Criteria:
- [ ] Agent ä½¿ç”¨ LangChain v1.0 create_agent() åˆ›å»º
- [ ] 3 ä¸ªå·¥å…·å·²å®ç° (search_documents, query_database, web_search)
- [ ] å·¥å…·è°ƒç”¨æˆåŠŸç‡ > 95%
- [ ] å·¥å…·æ‰§è¡Œå¹¶è¡ŒåŒ– (asyncio.TaskGroup)
- [ ] å“åº”ç”Ÿæˆæ­£ç¡®é›†æˆå·¥å…·ç»“æœ
- [ ] å•å…ƒæµ‹è¯•è¦†ç›– â‰¥80%
```

### ä»»åŠ¡åˆ†è§£

#### Task 2.2.1: LangChain Agent åŸºç¡€è®¾ç½®
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] LangChain v1.0 ä¾èµ–å®‰è£…
- [ ] create_agent åˆå§‹åŒ–
- [ ] Claude Sonnet 4.5 é›†æˆ
- [ ] Agent æµç¨‹æµ‹è¯•

```python
# backend/src/services/agent_service.py

from langchain.agents import create_agent
from langchain_anthropic import ChatAnthropic

class AgentService:
    """LangChain Agent æœåŠ¡"""

    def __init__(self, api_key: str):
        self.model = ChatAnthropic(
            model="claude-sonnet-4-5-20250929",
            api_key=api_key
        )

    async def create_agent(
        self,
        tools: list,
        system_prompt: str,
        middleware: list = None
    ):
        """
        åˆ›å»º Agent

        ä½¿ç”¨ LangChain v1.0 create_agent()
        """
        agent = create_agent(
            model=self.model,
            tools=tools,
            system_prompt=system_prompt,
            middleware=middleware or []
        )
        return agent

    async def run_agent(
        self,
        agent,
        user_message: str,
        conversation_history: list,
        rag_context: list
    ) -> dict:
        """è¿è¡Œ Agent"""
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            {"role": "user", "content": msg}
            for msg in conversation_history
        ]
        messages.append({"role": "user", "content": user_message})

        # æ³¨å…¥ RAG ä¸Šä¸‹æ–‡
        if rag_context:
            rag_prompt = self._format_rag_context(rag_context)
            messages.append({
                "role": "system",
                "content": f"Relevant documents:\n{rag_prompt}"
            })

        # è¿è¡Œ Agent
        result = await agent.ainvoke({
            "messages": messages,
            "tools_called": [],
            "tokens_used": 0
        })

        return result

    def _format_rag_context(self, rag_results: list) -> str:
        """æ ¼å¼åŒ– RAG ä¸Šä¸‹æ–‡"""
        formatted = []
        for result in rag_results:
            formatted.append(f"- {result['text']}")
        return "\n".join(formatted)
```

#### Task 2.2.2: search_documents å·¥å…·
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] å·¥å…·å®šä¹‰ (name, description, input schema)
- [ ] RAG æœç´¢å®ç°
- [ ] ç»“æœæ ¼å¼åŒ–
- [ ] é”™è¯¯å¤„ç†

```python
# backend/src/services/agent_tools.py

from langchain.tools import tool

@tool
def search_documents(
    query: str,
    user_id: str,
    conversation_id: str,
    limit: int = 5
) -> str:
    """
    Search uploaded documents using semantic similarity (RAG)

    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        user_id: ç”¨æˆ· ID
        conversation_id: å¯¹è¯ ID
        limit: è¿”å›ç»“æœæ•°

    Returns:
        æ ¼å¼åŒ–çš„æœç´¢ç»“æœå­—ç¬¦ä¸²
    """
    # å‘é‡åŒ–æŸ¥è¯¢
    query_embedding = embedding_service.embed(query)

    # æœç´¢ç›¸ä¼¼æ–‡æ¡£
    results = embedding_repo.search(
        query_embedding=query_embedding,
        user_id=user_id,
        limit=limit,
        threshold=0.7
    )

    # æ ¼å¼åŒ–ç»“æœ
    formatted = "Found documents:\n"
    for result in results:
        formatted += f"- {result['text'][:200]}... (score: {result['score']:.2f})\n"

    return formatted
```

#### Task 2.2.3: query_database å·¥å…·
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] å·¥å…·å®šä¹‰
- [ ] å®‰å…¨ SQL æ‰§è¡Œ (SELECT only)
- [ ] ç»“æœæ ¼å¼åŒ–
- [ ] SQL æ³¨å…¥é˜²æŠ¤

#### Task 2.2.4: web_search å·¥å…·å’Œå·¥å…·ç®¡ç†
**æ•…äº‹ç‚¹**: 4
**å®Œæˆæ ‡å‡†**:
- [ ] web_search å·¥å…·å®ç°
- [ ] å¹¶è¡Œå·¥å…·æ‰§è¡Œ (asyncio.TaskGroup)
- [ ] å·¥å…·ç»“æœåˆå¹¶
- [ ] é”™è¯¯æ¢å¤å’Œé‡è¯•

---

# ğŸ”§ EPIC 3: ä¸­é—´ä»¶å’Œç‰¹æ€§ (Week 3-4)

## Story 3.1: 5 å±‚ä¸­é—´ä»¶å®ç° + é”™è¯¯å¤„ç†

**æ•…äº‹ç‚¹**: 16 (13 + 3 for Task 3.1.4)
**ä¼˜å…ˆçº§**: P0 (é˜»å¡)
**åˆ†é…ç»™**: Backend Team
**æ ‡ç­¾**: middleware, architecture, observability, error-handling

### ä»»åŠ¡åˆ†è§£

#### Task 3.1.1: è®¤è¯å’Œè®°å¿†æ³¨å…¥ä¸­é—´ä»¶
**æ•…äº‹ç‚¹**: 4
**å®Œæˆæ ‡å‡†**:
- [ ] AuthenticationMiddleware å®ç°
- [ ] MemoryInjectionMiddleware å®ç°
- [ ] ä¸­é—´ä»¶å †æ ˆé›†æˆ
- [ ] å•å…ƒæµ‹è¯•

#### Task 3.1.2: å†…å®¹å®¡æ ¸å’Œå“åº”ç»“æ„åŒ–ä¸­é—´ä»¶
**æ•…äº‹ç‚¹**: 4
**å®Œæˆæ ‡å‡†**:
- [ ] ContentModerationMiddleware å®ç°
- [ ] ResponseStructuringMiddleware å®ç°
- [ ] ä¸­é—´ä»¶å †æ ˆé›†æˆ
- [ ] å•å…ƒæµ‹è¯•

#### Task 3.1.3: å®¡è®¡æ—¥å¿—ä¸­é—´ä»¶å’Œé›†æˆ
**æ•…äº‹ç‚¹**: 5
**å®Œæˆæ ‡å‡†**:
- [ ] AuditLoggingMiddleware å®ç°
- [ ] ç»“æ„åŒ–æ—¥å¿—é…ç½® (JSON)
- [ ] è¯·æ±‚è¿½è¸ª ID (X-Request-ID)
- [ ] ä¸­é—´ä»¶æ‰§è¡Œé¡ºåºéªŒè¯ (5 å±‚)
- [ ] é›†æˆæµ‹è¯•

#### Task 3.1.4: ä¸­é—´ä»¶é”™è¯¯å¤„ç†å’Œå®¹é”™ (A3 è¡¥æ•‘)
**æ•…äº‹ç‚¹**: 3
**ä¼˜å…ˆçº§**: P0 (é«˜)
**å®Œæˆæ ‡å‡†**:
- [ ] ä¸­é—´ä»¶è¶…æ—¶å¤„ç†æœºåˆ¶
- [ ] å‘é‡æœç´¢é™çº§ç­–ç•¥
- [ ] å¼‚å¸¸ä¼ æ’­å’Œè®°å½•
- [ ] å•å…ƒæµ‹è¯• (é”™è¯¯åœºæ™¯è¦†ç›–)

**å®ç°æŒ‡å—**:

```python
# backend/src/infrastructure/middleware/error_handling.py

from fastapi import Request
from typing import Callable
import asyncio
from enum import Enum

class FallbackStrategy(str, Enum):
    """ä¸­é—´ä»¶å¤±è´¥çš„é™çº§ç­–ç•¥"""
    RETURN_PARTIAL = "return_partial"  # è¿”å›éƒ¨åˆ†ç»“æœ
    RETRY_ONCE = "retry_once"          # é‡è¯•ä¸€æ¬¡
    SKIP_CONTEXT = "skip_context"      # è·³è¿‡è¯¥ä¸Šä¸‹æ–‡
    RETURN_ERROR = "return_error"       # è¿”å›é”™è¯¯

class MemoryInjectionMiddlewareWithErrorHandling:
    """å¸¦å®¹é”™æœºåˆ¶çš„è®°å¿†æ³¨å…¥ä¸­é—´ä»¶"""

    def __init__(self, timeout_ms: int = 200, strategy: FallbackStrategy = FallbackStrategy.SKIP_CONTEXT):
        self.timeout_ms = timeout_ms
        self.strategy = strategy

    async def __call__(self, request: Request, call_next: Callable) -> Any:
        """æ‰§è¡Œä¸­é—´ä»¶ï¼Œå«é”™è¯¯å¤„ç†"""
        user_id = request.state.user_id
        body = await request.json()
        conversation_id = body.get("conversation_id")
        user_message = body.get("message")

        try:
            # è®¾ç½®è¶…æ—¶ä¿æŠ¤
            async with asyncio.timeout(self.timeout_ms / 1000):
                # å¹¶è¡ŒæŸ¥è¯¢å†å²å’ŒRAGä¸Šä¸‹æ–‡
                async with asyncio.TaskGroup() as tg:
                    history_task = tg.create_task(
                        self._get_conversation_history(conversation_id)
                    )
                    rag_task = tg.create_task(
                        self._search_rag_context(user_message, user_id)
                    )

                request.state.conversation_history = await history_task
                request.state.rag_context = await rag_task
                request.state.memory_error = None

        except asyncio.TimeoutError:
            await logger.aerror(
                "memory_injection_timeout",
                request_id=request.headers.get("X-Request-ID"),
                timeout_ms=self.timeout_ms,
                strategy=self.strategy.value
            )
            await self._apply_fallback_strategy(request, strategy=self.strategy)

        except Exception as exc:
            await logger.aerror(
                "memory_injection_error",
                request_id=request.headers.get("X-Request-ID"),
                error=str(exc),
                strategy=self.strategy.value
            )
            await self._apply_fallback_strategy(request, strategy=self.strategy)

        try:
            return await call_next(request)
        except Exception as exc:
            # è®°å½•åœ¨åç»­ä¸­é—´ä»¶ä¸­å‘ç”Ÿçš„é”™è¯¯
            await logger.aerror(
                "middleware_chain_error",
                request_id=request.headers.get("X-Request-ID"),
                middleware="MemoryInjection",
                error=str(exc)
            )
            raise

    async def _apply_fallback_strategy(self, request: Request, strategy: FallbackStrategy):
        """åº”ç”¨é™çº§ç­–ç•¥"""
        if strategy == FallbackStrategy.SKIP_CONTEXT:
            # è·³è¿‡RAGä¸Šä¸‹æ–‡ï¼Œç»§ç»­å¤„ç†
            request.state.conversation_history = []
            request.state.rag_context = []
            request.state.memory_error = "rag_context_skipped_due_to_timeout"

        elif strategy == FallbackStrategy.RETURN_PARTIAL:
            # å°è¯•è¿”å›éƒ¨åˆ†ç»“æœ
            try:
                async with asyncio.timeout(100 / 1000):  # 100mså¿«é€ŸæŸ¥è¯¢
                    history = await self._get_conversation_history(
                        request.json().get("conversation_id")
                    )
                    request.state.conversation_history = history
                    request.state.rag_context = []
                    request.state.memory_error = "rag_context_unavailable"
            except:
                request.state.conversation_history = []
                request.state.rag_context = []

        elif strategy == FallbackStrategy.RETRY_ONCE:
            # å•æ¬¡é‡è¯•
            try:
                async with asyncio.timeout(self.timeout_ms / 1000 * 1.5):  # å»¶é•¿è¶…æ—¶
                    await asyncio.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿ
                    rag_context = await self._search_rag_context(
                        request.json().get("message"),
                        request.state.user_id
                    )
                    request.state.rag_context = rag_context
                    request.state.memory_error = None
            except:
                request.state.rag_context = []
                request.state.memory_error = "rag_retry_failed"

    async def _get_conversation_history(self, conversation_id: str) -> List[dict]:
        """è·å–å¯¹è¯å†å²"""
        # å®ç°...
        pass

    async def _search_rag_context(self, query: str, user_id: str) -> List[dict]:
        """æœç´¢RAGä¸Šä¸‹æ–‡"""
        # å®ç°...
        pass

# ä¸­é—´ä»¶æµ‹è¯•
@pytest.mark.asyncio
async def test_memory_injection_timeout():
    """æµ‹è¯•è¶…æ—¶å¤„ç†"""
    middleware = MemoryInjectionMiddlewareWithErrorHandling(
        timeout_ms=100,
        strategy=FallbackStrategy.SKIP_CONTEXT
    )
    # éªŒè¯è¶…æ—¶åæ­£ç¡®åº”ç”¨é™çº§ç­–ç•¥
    pass

@pytest.mark.asyncio
async def test_memory_injection_error_recovery():
    """æµ‹è¯•é”™è¯¯æ¢å¤"""
    middleware = MemoryInjectionMiddlewareWithErrorHandling(
        timeout_ms=200,
        strategy=FallbackStrategy.RETURN_PARTIAL
    )
    # éªŒè¯é”™è¯¯åä»èƒ½è¿”å›éƒ¨åˆ†ç»“æœ
    pass
```

**ç›¸å…³é…ç½®**:
```python
# backend/.env
MEMORY_INJECTION_TIMEOUT_MS=200          # å†…å­˜æ³¨å…¥è¶…æ—¶
MEMORY_INJECTION_FALLBACK=skip_context   # skip_context|return_partial|retry_once|return_error
VECTOR_SEARCH_TIMEOUT_MS=200             # å‘é‡æœç´¢è¶…æ—¶
VECTOR_SEARCH_RETRY_COUNT=1              # é‡è¯•æ¬¡æ•°
```

---

## Story 3.2: API ç«¯ç‚¹å®ç°

**æ•…äº‹ç‚¹**: 8
**ä¼˜å…ˆçº§**: P1 (é«˜)
**åˆ†é…ç»™**: Backend Team
**æ ‡ç­¾**: api, endpoints, rest

### ä»»åŠ¡åˆ†è§£

#### Task 3.2.1: å¯¹è¯ç«¯ç‚¹ (POST /conversations, GET /conversations/{id})
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] åˆ›å»ºå¯¹è¯ç«¯ç‚¹
- [ ] è·å–å¯¹è¯ç«¯ç‚¹
- [ ] åˆ—è¡¨å¯¹è¯ç«¯ç‚¹ (åˆ†é¡µ)
- [ ] è¾“å…¥éªŒè¯ (Pydantic)
- [ ] é”™è¯¯å¤„ç†

#### Task 3.2.2: æ¶ˆæ¯ç«¯ç‚¹å’Œ WebSocket
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] POST /conversations/{id}/messages ç«¯ç‚¹
- [ ] WebSocket ç«¯ç‚¹ /ws/{id}
- [ ] å®æ—¶æ¶ˆæ¯æµå¼å¤„ç†
- [ ] è¿æ¥ç®¡ç†å’Œå¿ƒè·³

#### Task 3.2.3: æ–‡æ¡£ä¸Šä¼ å’Œæœç´¢ç«¯ç‚¹
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] POST /documents/upload ç«¯ç‚¹
- [ ] POST /embeddings/search ç«¯ç‚¹
- [ ] æ–‡ä»¶éªŒè¯å’Œå¤§å°é™åˆ¶
- [ ] å¼‚æ­¥å¤„ç†é˜Ÿåˆ—

---

## Story 3.3: ç‰¹æ€§å®Œæˆã€é›†æˆ å’Œ ç”Ÿäº§å°±ç»ªæ€§

**æ•…äº‹ç‚¹**: 8 (5 + 3 for Task 3.3.4)
**ä¼˜å…ˆçº§**: P1 (é«˜, P0 for Task 3.3.4)
**åˆ†é…ç»™**: Backend Team
**æ ‡ç­¾**: features, integration, production-readiness, health-checks

### ä»»åŠ¡åˆ†è§£

#### Task 3.3.1: æµå¼å“åº”å®ç°
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] SSE (Server-Sent Events) æ”¯æŒ
- [ ] WebSocket æµå®ç°
- [ ] æµå¼ Agent å“åº”
- [ ] å‰ç«¯æµå¤„ç†

#### Task 3.3.2: é”™è¯¯å¤„ç†å’Œæ¢å¤
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] å…¨å±€å¼‚å¸¸å¤„ç†å™¨
- [ ] é”™è¯¯å“åº”æ ¼å¼
- [ ] é‡è¯•æœºåˆ¶
- [ ] ä¼˜é›…é™çº§

#### Task 3.3.3: åç«¯é›†æˆæµ‹è¯•
**æ•…äº‹ç‚¹**: 1
**å®Œæˆæ ‡å‡†**:
- [ ] ç«¯åˆ°ç«¯å¯¹è¯æµç¨‹æµ‹è¯•
- [ ] RAG é›†æˆæµ‹è¯•
- [ ] ä¸­é—´ä»¶å †æ ˆæµ‹è¯•
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•

#### Task 3.3.4: ä¼˜é›…å…³é—­å’Œå¥åº·æ£€æŸ¥ç«¯ç‚¹ (A8 è¡¥æ•‘ - Principle #7)
**æ•…äº‹ç‚¹**: 3
**ä¼˜å…ˆçº§**: P0 (ç”Ÿäº§å°±ç»ªæ€§)
**å®Œæˆæ ‡å‡†**:
- [ ] å¥åº·æ£€æŸ¥ç«¯ç‚¹ `/health` å®ç°
- [ ] SIGTERM ä¿¡å·å¤„ç†å™¨
- [ ] ä¼˜é›…å…³é—­æµç¨‹
- [ ] è¿æ¥æ¸…ç†å’Œèµ„æºé‡Šæ”¾
- [ ] å•å…ƒå’Œé›†æˆæµ‹è¯•

**å®ç°æŒ‡å—**:

```python
# backend/src/infrastructure/health.py

from fastapi import FastAPI, HTTPException
from typing import Dict, Any
import asyncio
import signal

class HealthChecker:
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""

    def __init__(self, app: FastAPI):
        self.app = app
        self.is_shutting_down = False

    async def check_database(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®åº“è¿æ¥"""
        try:
            async with AsyncSessionLocal() as session:
                # æ‰§è¡Œç®€å•æŸ¥è¯¢
                await session.execute(text("SELECT 1"))
            return {"status": "healthy", "latency_ms": 0}
        except Exception as e:
            return {"status": "unhealthy", "error": str(e)}

    async def check_vector_store(self) -> Dict[str, Any]:
        """æ£€æŸ¥å‘é‡å­˜å‚¨ (pgvector)"""
        try:
            async with AsyncSessionLocal() as session:
                # éªŒè¯pgvectoræ‰©å±•
                result = await session.execute(
                    text("SELECT extname FROM pg_extension WHERE extname='vector'")
                )
                if result.fetchone():
                    return {"status": "healthy", "extension": "pgvector"}
                else:
                    return {"status": "unhealthy", "error": "pgvector extension not installed"}
        except Exception as e:
            return {"status": "unhealthy", "error": str(e)}

    async def check_redis(self) -> Dict[str, Any]:
        """æ£€æŸ¥Redisè¿æ¥ (ç¼“å­˜)"""
        try:
            # å°è¯•ping Redis
            await redis_client.ping()
            return {"status": "healthy"}
        except Exception as e:
            return {"status": "unhealthy", "error": str(e)}

    async def check_llm_api(self) -> Dict[str, Any]:
        """æ£€æŸ¥LLM APIè¿æ¥"""
        try:
            # è°ƒç”¨Anthropic API
            response = await anthropic_client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=10,
                messages=[{"role": "user", "content": "ping"}]
            )
            return {"status": "healthy", "model": "claude-sonnet-4-5-20250929"}
        except Exception as e:
            return {"status": "unhealthy", "error": str(e)}

    async def get_health_status(self) -> Dict[str, Any]:
        """è·å–å®Œæ•´çš„å¥åº·çŠ¶æ€"""
        if self.is_shutting_down:
            return {
                "status": "shutting_down",
                "timestamp": datetime.utcnow().isoformat()
            }

        # å¹¶è¡Œæ£€æŸ¥æ‰€æœ‰æœåŠ¡
        async with asyncio.TaskGroup() as tg:
            db_task = tg.create_task(self.check_database())
            vector_task = tg.create_task(self.check_vector_store())
            redis_task = tg.create_task(self.check_redis())
            llm_task = tg.create_task(self.check_llm_api())

        db_status = await db_task
        vector_status = await vector_task
        redis_status = await redis_task
        llm_status = await llm_task

        # è®¡ç®—æ€»ä½“çŠ¶æ€
        all_healthy = all([
            db_status["status"] == "healthy",
            vector_status["status"] == "healthy",
            redis_status["status"] == "healthy",
            llm_status["status"] == "healthy"
        ])

        return {
            "status": "healthy" if all_healthy else "degraded",
            "timestamp": datetime.utcnow().isoformat(),
            "checks": {
                "database": db_status,
                "vector_store": vector_status,
                "redis": redis_status,
                "llm_api": llm_status
            }
        }

# ä¼˜é›…å…³é—­å¤„ç†
class GracefulShutdownHandler:
    """ä¼˜é›…å…³é—­å¤„ç†å™¨"""

    def __init__(self, app: FastAPI, shutdown_timeout_seconds: int = 30):
        self.app = app
        self.shutdown_timeout = shutdown_timeout_seconds
        self.active_requests = 0
        self.lock = asyncio.Lock()

    async def on_startup(self):
        """åº”ç”¨å¯åŠ¨"""
        await logger.ainfo("app_starting", version="1.0.0")

    async def on_shutdown(self):
        """åº”ç”¨å…³é—­ - SIGTERMå¤„ç†"""
        await logger.ainfo("app_shutdown_initiated", timeout_seconds=self.shutdown_timeout)

        # ç­‰å¾…æ´»è·ƒè¯·æ±‚å®Œæˆï¼ˆæœ€å¤š30ç§’ï¼‰
        start_time = time.time()
        while self.active_requests > 0:
            elapsed = time.time() - start_time
            if elapsed > self.shutdown_timeout:
                await logger.awarn(
                    "shutdown_timeout_exceeded",
                    active_requests=self.active_requests,
                    elapsed_seconds=elapsed
                )
                break

            await logger.ainfo(
                "waiting_for_requests_completion",
                active_requests=self.active_requests,
                elapsed_seconds=elapsed
            )
            await asyncio.sleep(1)

        # æ¸…ç†èµ„æº
        await self._cleanup_resources()
        await logger.ainfo("app_shutdown_complete")

    async def _cleanup_resources(self):
        """æ¸…ç†æ•°æ®åº“è¿æ¥ã€ç¼“å­˜ç­‰"""
        try:
            # å…³é—­æ•°æ®åº“å¼•æ“
            if engine:
                await engine.dispose()

            # å…³é—­Redisè¿æ¥
            if redis_client:
                await redis_client.close()

            # å…¶ä»–æ¸…ç†æ“ä½œ
            await logger.ainfo("all_resources_cleaned_up")
        except Exception as e:
            await logger.aerror("resource_cleanup_error", error=str(e))

    def track_request_start(self):
        """è¯·æ±‚å¼€å§‹"""
        self.active_requests += 1

    def track_request_end(self):
        """è¯·æ±‚ç»“æŸ"""
        self.active_requests = max(0, self.active_requests - 1)

# FastAPIåº”ç”¨é›†æˆ
def setup_health_and_shutdown(app: FastAPI):
    """è®¾ç½®å¥åº·æ£€æŸ¥å’Œä¼˜é›…å…³é—­"""

    health_checker = HealthChecker(app)
    shutdown_handler = GracefulShutdownHandler(app)

    # æ³¨å†Œå¯åŠ¨å’Œå…³é—­äº‹ä»¶
    app.add_event_handler("startup", shutdown_handler.on_startup)
    app.add_event_handler("shutdown", shutdown_handler.on_shutdown)

    # å¥åº·æ£€æŸ¥ç«¯ç‚¹
    @app.get("/health", tags=["monitoring"])
    async def health_check() -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥ç«¯ç‚¹ - æœºå™¨å¯è¯»"""
        status = await health_checker.get_health_status()

        # è®¾ç½®HTTPçŠ¶æ€ç 
        if status["status"] == "healthy":
            return status
        elif status["status"] == "degraded":
            raise HTTPException(status_code=503, detail=status)
        else:  # shutting_down
            raise HTTPException(status_code=503, detail=status)

    @app.get("/health/live", tags=["monitoring"])
    async def liveness_probe() -> Dict[str, str]:
        """å­˜æ´»æ€§æ¢é’ˆ - Kubernetesç”¨"""
        if shutdown_handler.active_requests < 0:
            raise HTTPException(status_code=500)
        return {"status": "alive"}

    @app.get("/health/ready", tags=["monitoring"])
    async def readiness_probe() -> Dict[str, str]:
        """å°±ç»ªæ€§æ¢é’ˆ - Kubernetesç”¨"""
        status = await health_checker.get_health_status()
        if status["status"] == "healthy":
            return {"status": "ready"}
        else:
            raise HTTPException(status_code=503, detail="Not ready")

    # è¯·æ±‚è·Ÿè¸ªä¸­é—´ä»¶
    @app.middleware("http")
    async def track_requests(request: Request, call_next):
        """è¿½è¸ªæ´»è·ƒè¯·æ±‚æ•°"""
        shutdown_handler.track_request_start()
        try:
            return await call_next(request)
        finally:
            shutdown_handler.track_request_end()

    # æ³¨å†ŒSIGTERMå¤„ç†å™¨
    def handle_sigterm():
        """å¤„ç†SIGTERMä¿¡å·"""
        asyncio.create_task(app.router.shutdown())

    signal.signal(signal.SIGTERM, lambda signum, frame: handle_sigterm())

# æµ‹è¯•
@pytest.mark.asyncio
async def test_health_check_all_healthy():
    """æµ‹è¯•å¥åº·æ£€æŸ¥ - æ‰€æœ‰æœåŠ¡æ­£å¸¸"""
    checker = HealthChecker(mock_app)
    status = await checker.get_health_status()

    assert status["status"] == "healthy"
    assert status["checks"]["database"]["status"] == "healthy"
    assert status["checks"]["vector_store"]["status"] == "healthy"

@pytest.mark.asyncio
async def test_graceful_shutdown():
    """æµ‹è¯•ä¼˜é›…å…³é—­"""
    handler = GracefulShutdownHandler(mock_app, shutdown_timeout_seconds=5)

    # æ¨¡æ‹Ÿæ´»è·ƒè¯·æ±‚
    handler.active_requests = 3
    await handler.on_shutdown()

    # éªŒè¯èµ„æºå·²æ¸…ç†
    assert handler.active_requests >= 0
```

**Kubernetes é›†æˆ** (éƒ¨ç½²ç”¨):
```yaml
# kubernetes/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: langchain-ai-api
spec:
  template:
    spec:
      containers:
      - name: api
        image: langchain-ai:latest

        # å¥åº·æ£€æŸ¥é…ç½®
        livenessProbe:
          httpGet:
            path: /health/live
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3

        readinessProbe:
          httpGet:
            path: /health/ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2

        # ä¼˜é›…å…³é—­
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 15"]  # ç»™æ—¶é—´å®Œæˆè¯·æ±‚

        terminationGracePeriodSeconds: 45  # 45ç§’è¶…æ—¶
```

**ç›‘æ§å’Œå‘Šè­¦**:
```prometheus
# prometheus/rules.yaml
groups:
  - name: api_health
    rules:
      - alert: APIUnhealthy
        expr: up{job="langchain-api"} == 0
        for: 1m
        annotations:
          summary: "API is unhealthy"

      - alert: HighActiveRequests
        expr: active_requests > 1000
        for: 5m
        annotations:
          summary: "High number of active requests"

      - alert: DatabaseUnhealthy
        expr: health_check_database_status != 1
        for: 2m
        annotations:
          summary: "Database connection failed"
```

---

# ğŸ¨ EPIC 4: å‰ç«¯å¼€å‘ (Week 4-5)

## Story 4.1: åŸºç¡€ UI ç»„ä»¶

**æ•…äº‹ç‚¹**: 13
**ä¼˜å…ˆçº§**: P1 (é«˜)
**åˆ†é…ç»™**: Frontend Team
**æ ‡ç­¾**: ui, components, tailark

### ä»»åŠ¡åˆ†è§£

#### Task 4.1.1: èŠå¤©ç•Œé¢å’Œæ¶ˆæ¯æ˜¾ç¤º
**æ•…äº‹ç‚¹**: 5
**å®Œæˆæ ‡å‡†**:
- [ ] ChatInterface ä¸»ç»„ä»¶
- [ ] ChatMessage æ¶ˆæ¯ç»„ä»¶
- [ ] MessageList åˆ—è¡¨ç»„ä»¶
- [ ] TypingIndicator è¾“å…¥æŒ‡ç¤ºå™¨
- [ ] Tailark Hero é›†æˆ

#### Task 4.1.2: æ¶ˆæ¯è¾“å…¥å’Œè¡¨å•
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] ChatInput è¾“å…¥æ¡†
- [ ] è¡¨æƒ…å’Œé™„ä»¶æ”¯æŒ
- [ ] è¡¨å•éªŒè¯ (React Hook Form + Zod)
- [ ] æäº¤å¤„ç†

#### Task 4.1.3: å¯¹è¯ç®¡ç† UI
**æ•…äº‹ç‚¹**: 5
**å®Œæˆæ ‡å‡†**:
- [ ] ConversationList åˆ—è¡¨
- [ ] ConversationHeader å¤´éƒ¨
- [ ] å¯¹è¯åˆ›å»ºå¯¹è¯æ¡†
- [ ] å¯¹è¯åˆ é™¤ç¡®è®¤
- [ ] æœç´¢å’Œè¿‡æ»¤

---

## Story 4.2: æ–‡æ¡£ç®¡ç†å’Œé«˜çº§ç‰¹æ€§

**æ•…äº‹ç‚¹**: 8
**ä¼˜å…ˆçº§**: P1 (é«˜)
**åˆ†é…ç»™**: Frontend Team
**æ ‡ç­¾**: ui, file-upload, features

### ä»»åŠ¡åˆ†è§£

#### Task 4.2.1: æ–‡æ¡£ä¸Šä¼ ç•Œé¢
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] FileDropZone æ‹–æ‹½åŒºåŸŸ
- [ ] DocumentUploadForm ä¸Šä¼ è¡¨å•
- [ ] UploadProgress è¿›åº¦æ¡
- [ ] æ–‡ä»¶éªŒè¯åé¦ˆ

#### Task 4.2.2: å®æ—¶é€šä¿¡é›†æˆ
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] Socket.IO è¿æ¥
- [ ] æ¶ˆæ¯æ¥æ”¶å¤„ç†
- [ ] é”™è¯¯é‡æ–°è¿æ¥
- [ ] è¿æ¥çŠ¶æ€æ˜¾ç¤º

#### Task 4.2.3: çŠ¶æ€ç®¡ç†å’Œæ•°æ®è·å–
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] Zustand store åˆ›å»º
- [ ] TanStack Query é›†æˆ
- [ ] API å®¢æˆ·ç«¯æœåŠ¡
- [ ] ç¼“å­˜ç­–ç•¥

---

## Story 4.3: æ ·å¼å’Œä¼˜åŒ–

**æ•…äº‹ç‚¹**: 5
**ä¼˜å…ˆçº§**: P2 (ä¸­)
**åˆ†é…ç»™**: Frontend Team
**æ ‡ç­¾**: styling, performance, ux

### ä»»åŠ¡åˆ†è§£

#### Task 4.3.1: Tailwind æ ·å¼å’Œå“åº”å¼è®¾è®¡
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] Tailwind é…ç½®
- [ ] å“åº”å¼å¸ƒå±€ (mobile, tablet, desktop)
- [ ] æ·±è‰²æ¨¡å¼æ”¯æŒ
- [ ] åŠ¨ç”»å’Œè¿‡æ¸¡

#### Task 4.3.2: æ€§èƒ½ä¼˜åŒ–å’Œ SEO
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] ä»£ç åˆ†å‰² (Code Splitting)
- [ ] å›¾ç‰‡ä¼˜åŒ–
- [ ] è·¯ç”±æ‡’åŠ è½½
- [ ] ç”Ÿäº§æ„å»ºä¼˜åŒ–

#### Task 4.3.3: å¯è®¿é—®æ€§å’Œç”¨æˆ·ä½“éªŒ
**æ•…äº‹ç‚¹**: 1
**å®Œæˆæ ‡å‡†**:
- [ ] ARIA æ ‡ç­¾
- [ ] é”®ç›˜å¯¼èˆª
- [ ] å¯¹æ¯”åº¦æ£€æŸ¥
- [ ] ç”¨æˆ·åé¦ˆ (Toast)

---

# ğŸ§ª EPIC 5: æµ‹è¯•å’Œä¼˜åŒ– (Week 5-6)

## Story 5.1: å•å…ƒå’Œé›†æˆæµ‹è¯•

**æ•…äº‹ç‚¹**: 13
**ä¼˜å…ˆçº§**: P0 (é˜»å¡)
**åˆ†é…ç»™**: QA Team
**æ ‡ç­¾**: testing, quality, coverage

### ä»»åŠ¡åˆ†è§£

#### Task 5.1.1: åç«¯å•å…ƒæµ‹è¯•
**æ•…äº‹ç‚¹**: 5
**å®Œæˆæ ‡å‡†**:
- [ ] Services å•å…ƒæµ‹è¯• (â‰¥90%)
- [ ] Repositories å•å…ƒæµ‹è¯• (â‰¥90%)
- [ ] Models éªŒè¯æµ‹è¯•
- [ ] å•å…ƒæµ‹è¯•è¿è¡ŒæˆåŠŸ
- [ ] è¦†ç›–ç‡æŠ¥å‘Šç”Ÿæˆ

#### Task 5.1.2: åç«¯é›†æˆæµ‹è¯•
**æ•…äº‹ç‚¹**: 4
**å®Œæˆæ ‡å‡†**:
- [ ] API ç«¯ç‚¹æµ‹è¯•
- [ ] ä¸­é—´ä»¶æµç¨‹æµ‹è¯•
- [ ] RAG æµç¨‹æµ‹è¯•
- [ ] Agent æ‰§è¡Œæµ‹è¯•

#### Task 5.1.3: å‰ç«¯å•å…ƒå’Œ E2E æµ‹è¯•
**æ•…äº‹ç‚¹**: 4
**å®Œæˆæ ‡å‡†**:
- [ ] ç»„ä»¶å•å…ƒæµ‹è¯• (Jest)
- [ ] Hooks å•å…ƒæµ‹è¯•
- [ ] Utils å•å…ƒæµ‹è¯•
- [ ] E2E æµ‹è¯• (Playwright)

---

## Story 5.2: æ€§èƒ½ä¼˜åŒ–

**æ•…äº‹ç‚¹**: 8
**ä¼˜å…ˆçº§**: P1 (é«˜)
**åˆ†é…ç»™**: Backend + Frontend Team
**æ ‡ç­¾**: performance, optimization

### ä»»åŠ¡åˆ†è§£

#### Task 5.2.1: æ•°æ®åº“å’ŒæŸ¥è¯¢ä¼˜åŒ–
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] æŸ¥è¯¢æ€§èƒ½åˆ†æ
- [ ] ç´¢å¼•ä¼˜åŒ–éªŒè¯
- [ ] N+1 é—®é¢˜ä¿®å¤
- [ ] ç¼“å­˜ç­–ç•¥å®ç° (Redis)

#### Task 5.2.2: API å“åº”æ—¶é—´ä¼˜åŒ–
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] ç®€å•æŸ¥è¯¢ â‰¤500ms
- [ ] RAG æŸ¥è¯¢ â‰¤2000ms
- [ ] å‘é‡æœç´¢ â‰¤200ms
- [ ] è´Ÿè½½æµ‹è¯•éªŒè¯

#### Task 5.2.3: å‰ç«¯æ€§èƒ½ä¼˜åŒ–
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] åŒ…å¤§å°ä¼˜åŒ–
- [ ] é¦–å±åŠ è½½æ—¶é—´ â‰¤3s
- [ ] Lighthouse è¯„åˆ† â‰¥90
- [ ] Core Web Vitals

---

## Story 5.3: ä»£ç è´¨é‡å’Œæ–‡æ¡£

**æ•…äº‹ç‚¹**: 5
**ä¼˜å…ˆçº§**: P1 (é«˜)
**åˆ†é…ç»™**: Entire Team
**æ ‡ç­¾**: quality, documentation, testing

### ä»»åŠ¡åˆ†è§£

#### Task 5.3.1: ç±»å‹æ£€æŸ¥å’Œ Linting
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] mypy --strict é€šè¿‡ (0 errors)
- [ ] pylint/flake8 æ— é”™è¯¯
- [ ] eslint/prettier é€šè¿‡
- [ ] ä»£ç å®¡æŸ¥

#### Task 5.3.2: æ–‡æ¡£ç¼–å†™
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] API æ–‡æ¡£ (Swagger/OpenAPI)
- [ ] README å’Œå¿«é€Ÿå¼€å§‹
- [ ] å¼€å‘æŒ‡å—
- [ ] éƒ¨ç½²æŒ‡å—

#### Task 5.3.3: å®‰å…¨å®¡è®¡
**æ•…äº‹ç‚¹**: 1
**å®Œæˆæ ‡å‡†**:
- [ ] å®‰å…¨æ‰«æ (SAST)
- [ ] ä¾èµ–æ¼æ´æ£€æŸ¥
- [ ] æ—  SQL æ³¨å…¥æ¼æ´
- [ ] æ—  XSS æ¼æ´

---

# ğŸš€ EPIC 6: éƒ¨ç½²å’Œä¸Šçº¿ (Week 6-7)

## Story 6.1: éƒ¨ç½²å‡†å¤‡å’Œ CI/CD

**æ•…äº‹ç‚¹**: 8
**ä¼˜å…ˆçº§**: P0 (é˜»å¡)
**åˆ†é…ç»™**: DevOps + Backend Lead
**æ ‡ç­¾**: deployment, ci-cd, docker

### ä»»åŠ¡åˆ†è§£

#### Task 6.1.1: Docker å’Œé•œåƒæ„å»º
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] Dockerfile åˆ›å»ºå’Œæµ‹è¯•
- [ ] Docker é•œåƒæ„å»ºæˆåŠŸ
- [ ] é•œåƒå¤§å°ä¼˜åŒ–
- [ ] é•œåƒæ¨é€åˆ°ä»“åº“

#### Task 6.1.2: GitHub Actions CI/CD
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] è‡ªåŠ¨åŒ–æµ‹è¯•æµç¨‹
- [ ] è‡ªåŠ¨åŒ–æ„å»ºæµç¨‹
- [ ] è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹ (Coolify)
- [ ] CI/CD æµç¨‹éªŒè¯

#### Task 6.1.3: ç›‘æ§å’Œå‘Šè­¦é…ç½®
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] Prometheus æŒ‡æ ‡é…ç½®
- [ ] Grafana ä»ªè¡¨æ¿åˆ›å»º
- [ ] å‘Šè­¦è§„åˆ™é…ç½®
- [ ] ç›‘æ§éªŒè¯

---

## Story 6.2: ç”Ÿäº§éƒ¨ç½²

**æ•…äº‹ç‚¹**: 5
**ä¼˜å…ˆçº§**: P0 (é˜»å¡)
**åˆ†é…ç»™**: DevOps + Backend Lead
**æ ‡ç­¾**: deployment, production, coolify

### ä»»åŠ¡åˆ†è§£

#### Task 6.2.1: æµ‹è¯•ç¯å¢ƒéƒ¨ç½²
**æ•…äº‹ç‚¹**: 2
**å®Œæˆæ ‡å‡†**:
- [ ] Coolify é…ç½®
- [ ] æ•°æ®åº“åˆå§‹åŒ–
- [ ] ç¯å¢ƒå˜é‡è®¾ç½®
- [ ] éƒ¨ç½²éªŒè¯

#### Task 6.2.2: ç”Ÿäº§éƒ¨ç½²å’ŒéªŒè¯
**æ•…äº‹ç‚¹**: 3
**å®Œæˆæ ‡å‡†**:
- [ ] é‡‘ä¸é›€éƒ¨ç½² (5% æµé‡)
- [ ] ç›‘æ§éªŒè¯
- [ ] å¥åº·æ£€æŸ¥é€šè¿‡
- [ ] å…¨é‡éƒ¨ç½²

---

# ğŸ“Š Story ä¼˜å…ˆçº§å’Œæ—¶é—´çº¿

## æŒ‰ä¼˜å…ˆçº§æ’åº

### P0 (é˜»å¡ - Week 1-4)
1. Story 1.1: æ•°æ®åº“è®¾è®¡ (5 pts, Day 1-5)
2. Story 1.2: å¼‚æ­¥å­˜å‚¨åº“ (8 pts, Day 6-12)
3. Story 1.3: API æ¡†æ¶ (5 pts, Day 13-14)
4. Story 2.1: RAG ç®¡é“ (13 pts, Day 15-23)
5. Story 2.2: Agent å®ç° (13 pts, Day 24-32)
6. Story 3.1: ä¸­é—´ä»¶ (13 pts, Day 33-40)
7. Story 6.1: éƒ¨ç½²å‡†å¤‡ (8 pts, Day 41-42)
8. Story 6.2: ç”Ÿäº§éƒ¨ç½² (5 pts, Day 43-42)

### P1 (é«˜ - Week 4-6)
1. Story 3.2: API ç«¯ç‚¹ (8 pts, Day 33-37)
2. Story 3.3: ç‰¹æ€§å®Œæˆ (5 pts, Day 38-40)
3. Story 4.1: UI ç»„ä»¶ (13 pts, Day 41-50)
4. Story 4.2: æ–‡æ¡£ç®¡ç† (8 pts, Day 51-55)
5. Story 5.1: æµ‹è¯• (13 pts, Day 56-65)
6. Story 5.2: æ€§èƒ½ä¼˜åŒ– (8 pts, Day 66-71)

### P2 (ä¸­ - Week 5-6)
1. Story 4.3: æ ·å¼ä¼˜åŒ– (5 pts, Day 56-60)
2. Story 5.3: ä»£ç è´¨é‡ (5 pts, Day 71-75)

---

# ğŸ“‹ å®Œæˆæ ‡å‡† (Definition of Done)

æ¯ä¸ª Story/Task å®Œæˆå¿…é¡»æ»¡è¶³:

- [ ] ä»£ç å®ç°å®Œæˆ
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡ä¸”è¦†ç›–ç‡ç¬¦åˆè¦æ±‚
- [ ] é›†æˆæµ‹è¯•é€šè¿‡
- [ ] mypy --strict é€šè¿‡
- [ ] Linting æ— é”™è¯¯
- [ ] ä»£ç å®¡æŸ¥é€šè¿‡ (â‰¥1 reviewer)
- [ ] æ–‡æ¡£æ›´æ–°å®Œæˆ
- [ ] ç›¸å…³ç›‘æ§/å‘Šè­¦å·²é…ç½®
- [ ] æ€§èƒ½æŒ‡æ ‡ç¬¦åˆç›®æ ‡
- [ ] æ²¡æœ‰æ–°çš„å®‰å…¨æ¼æ´

---

# ğŸ”— ä¾èµ–å…³ç³»

```
Story 1.1 (æ•°æ®åº“)
    â†“
Story 1.2 (å­˜å‚¨åº“) â†’ Story 2.1 (RAG) â†’ Story 2.2 (Agent)
    â†“                      â†“             â†“
Story 1.3 (APIæ¡†æ¶) â†’ Story 3.1 (ä¸­é—´ä»¶) â†’ Story 3.2 (ç«¯ç‚¹) â†’ Story 3.3 (é›†æˆ)
                                              â†“
                                          Story 4.1 (å‰ç«¯) â†’ Story 4.2 (é«˜çº§) â†’ Story 4.3 (æ ·å¼)
                                              â†“
                                          Story 5.1 (æµ‹è¯•) â†’ Story 5.2 (æ€§èƒ½) â†’ Story 5.3 (è´¨é‡)
                                              â†“
                                          Story 6.1 (CI/CD) â†’ Story 6.2 (éƒ¨ç½²)
```

---

# ğŸ“Š æ€»ä½“å·¥ä½œé‡ä¼°ç®—

| Epic | Story | Points | å·¥ä½œæ—¥ | å¼€å§‹ | ç»“æŸ |
|------|-------|--------|--------|------|------|
| 1 | 1.1 | 5 | 2.5 | D1 | D5 |
| 1 | 1.2 | 8 | 4 | D6 | D12 |
| 1 | 1.3 | 5 | 2.5 | D13 | D15 |
| 2 | 2.1 | 13 | 6.5 | D16 | D23 |
| 2 | 2.2 | 13 | 6.5 | D24 | D32 |
| 3 | 3.1 | 13 | 6.5 | D33 | D40 |
| 3 | 3.2 | 8 | 4 | D33 | D37 |
| 3 | 3.3 | 5 | 2.5 | D38 | D40 |
| 4 | 4.1 | 13 | 6.5 | D41 | D50 |
| 4 | 4.2 | 8 | 4 | D51 | D55 |
| 4 | 4.3 | 5 | 2.5 | D56 | D60 |
| 5 | 5.1 | 13 | 6.5 | D56 | D65 |
| 5 | 5.2 | 8 | 4 | D66 | D71 |
| 5 | 5.3 | 5 | 2.5 | D72 | D75 |
| 6 | 6.1 | 8 | 4 | D76 | D80 |
| 6 | 6.2 | 5 | 2.5 | D81 | D83 |
| **æ€»è®¡** | **16** | **138** | **69** | **D1** | **D45** |

**æ›´æ–°**: +11 æ•…äº‹ç‚¹ (3 ä¸ª Açº§è¡¥æ•‘ä»»åŠ¡):
- Task 3.1.4: ä¸­é—´ä»¶é”™è¯¯å¤„ç† (+3 pts)
- Task 2.1.5: é•¿å¯¹è¯æ€»ç»“ (+5 pts)
- Task 3.3.4: ä¼˜é›…å…³é—­å’Œå¥åº·æ£€æŸ¥ (+3 pts)
- æ€»è®¡: 127 â†’ **138 æ•…äº‹ç‚¹** | 63.5 â†’ **69 å·¥ä½œæ—¥** | 6-7 å‘¨ â†’ **~7.5 å‘¨**

**æ—¥æœŸ**:
- 1 Story Point = 0.5 å·¥ä½œæ—¥
- æ¯å‘¨ 5 ä¸ªå·¥ä½œæ—¥
- æ€»è®¡: ~3 å‘¨åŠå®ŒæˆåŸºç¡€åŠŸèƒ½ï¼ŒåŠ ä¸Š 1.5 å‘¨æµ‹è¯•å’Œéƒ¨ç½²

---

**ä»»åŠ¡åˆ†è§£ç‰ˆæœ¬**: 1.0.0
**æœ€åæ›´æ–°**: 2025-11-16
**çŠ¶æ€**: ğŸ“‹ Ready for Development
**ä¸‹ä¸€æ­¥**: æŒ‰ä¼˜å…ˆçº§å¼€å§‹å®ç° Story 1.1
