# Logstash Configuration for LangChain AI Application
# Collects logs from Nginx, FastAPI, and Supervisor

input {
  # ============================================
  # File Input - Application Logs
  # ============================================
  file {
    path => "/var/log/app/backend.log"
    type => "fastapi"
    codec => multiline {
      pattern => "^%{TIMESTAMP_ISO8601}"
      negate => true
      what => "previous"
    }
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb_backend"
  }

  file {
    path => "/var/log/app/backend_error.log"
    type => "fastapi-error"
    codec => multiline {
      pattern => "^%{TIMESTAMP_ISO8601}"
      negate => true
      what => "previous"
    }
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb_backend_error"
  }

  file {
    path => "/var/log/app/nginx_access.log"
    type => "nginx-access"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb_nginx_access"
  }

  file {
    path => "/var/log/app/nginx_error.log"
    type => "nginx-error"
    codec => multiline {
      pattern => "^%{YEAR}/%{MONTHNUM}/%{MONTHDAY}"
      negate => true
      what => "previous"
    }
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb_nginx_error"
  }

  file {
    path => "/var/log/app/health_monitor.log"
    type => "health-monitor"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb_health_monitor"
  }

  # ============================================
  # TCP Input - Real-time Logs
  # ============================================
  tcp {
    port => 5000
    codec => json
    type => "json-logs"
  }

  # ============================================
  # Beats Input - Filebeat/Metricbeat
  # ============================================
  beats {
    port => 5044
    type => "beats"
  }
}

filter {
  # ============================================
  # FastAPI Application Logs
  # ============================================
  if [type] == "fastapi" or [type] == "fastapi-error" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{DATA:logger} - %{LOGLEVEL:level} - %{GREEDYDATA:message}"
      }
      overwrite => ["message"]
      patterns_dir => ["/usr/share/logstash/patterns"]
    }

    # Parse JSON logs if present
    if [message] =~ /^\{.*\}$/ {
      json {
        source => "message"
        target => "json_data"
      }

      # Extract common fields
      mutate {
        add_field => {
          "request_id" => "%{[json_data][request_id]}"
          "user_id" => "%{[json_data][user_id]}"
          "endpoint" => "%{[json_data][endpoint]}"
          "duration_ms" => "%{[json_data][duration_ms]}"
        }
        remove_field => ["json_data"]
      }
    }

    # Parse timestamp
    date {
      match => ["timestamp", "ISO8601"]
      target => "@timestamp"
    }

    # Add component tag
    mutate {
      add_field => {
        "component" => "backend"
        "service" => "langchain-ai"
      }
    }
  }

  # ============================================
  # Nginx Access Logs
  # ============================================
  if [type] == "nginx-access" {
    grok {
      match => {
        "message" => '%{IPORHOST:remote_addr} - %{DATA:remote_user} \[%{HTTPDATE:timestamp}\] "%{WORD:method} %{DATA:request} HTTP/%{NUMBER:http_version}" %{NUMBER:status} %{NUMBER:body_bytes_sent} "%{DATA:http_referer}" "%{DATA:http_user_agent}"'
      }
      patterns_dir => ["/usr/share/logstash/patterns"]
    }

    # Parse timestamp
    date {
      match => ["timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
      target => "@timestamp"
    }

    # Convert numeric fields
    mutate {
      convert => {
        "status" => "integer"
        "body_bytes_sent" => "integer"
        "http_version" => "float"
      }
      add_field => {
        "component" => "nginx"
        "log_type" => "access"
      }
    }

    # Geo IP lookup (if geoip filter is available)
    # geoip {
    #   source => "remote_addr"
    #   target => "geoip"
    # }
  }

  # ============================================
  # Nginx Error Logs
  # ============================================
  if [type] == "nginx-error" {
    grok {
      match => {
        "message" => "%{YEAR:year}/%{MONTHNUM:month}/%{MONTHDAY:day} %{TIME:time} \[%{LOGLEVEL:level}\] %{NUMBER:pid}#%{NUMBER:tid}: %{GREEDYDATA:error_message}"
      }
      patterns_dir => ["/usr/share/logstash/patterns"]
    }

    # Construct timestamp
    mutate {
      add_field => {
        "timestamp" => "%{year}-%{month}-%{day} %{time}"
      }
    }

    date {
      match => ["timestamp", "yyyy-MM-dd HH:mm:ss"]
      target => "@timestamp"
    }

    mutate {
      add_field => {
        "component" => "nginx"
        "log_type" => "error"
      }
      remove_field => ["year", "month", "day", "time", "timestamp"]
    }
  }

  # ============================================
  # Health Monitor Logs
  # ============================================
  if [type] == "health-monitor" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{LOGLEVEL:level} - %{GREEDYDATA:message}"
      }
      overwrite => ["message"]
    }

    date {
      match => ["timestamp", "ISO8601"]
      target => "@timestamp"
    }

    mutate {
      add_field => {
        "component" => "monitoring"
        "service" => "health-monitor"
      }
    }
  }

  # ============================================
  # Common Filters for All Logs
  # ============================================

  # Add environment and cluster information
  mutate {
    add_field => {
      "environment" => "${ENVIRONMENT:production}"
      "cluster" => "coolify"
      "hostname" => "${HOSTNAME:localhost}"
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => ["host", "path", "@version"]
  }

  # Add error detection
  if [level] == "ERROR" or [level] == "error" or [status] >= 500 {
    mutate {
      add_tag => ["error"]
    }
  }

  # Add warning detection
  if [level] == "WARNING" or [level] == "warning" or [level] == "warn" {
    mutate {
      add_tag => ["warning"]
    }
  }

  # Add slow request detection (> 3 seconds)
  if [duration_ms] and [duration_ms] > 3000 {
    mutate {
      add_tag => ["slow_request"]
    }
  }
}

output {
  # ============================================
  # Elasticsearch Output
  # ============================================
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOSTS:elasticsearch:9200}"]
    index => "langchain-ai-%{+YYYY.MM.dd}"
    document_type => "_doc"

    # Index lifecycle management
    ilm_enabled => true
    ilm_rollover_alias => "langchain-ai"
    ilm_pattern => "{now/d}-000001"
    ilm_policy => "langchain-ai-policy"

    # Retry configuration
    retry_max_interval => 64
    retry_initial_interval => 2
  }

  # ============================================
  # Conditional Outputs
  # ============================================

  # Send errors to separate index for quick access
  if "error" in [tags] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOSTS:elasticsearch:9200}"]
      index => "langchain-ai-errors-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
  }

  # Send slow requests to performance analysis index
  if "slow_request" in [tags] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOSTS:elasticsearch:9200}"]
      index => "langchain-ai-performance-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
  }

  # ============================================
  # Debug Output (disabled in production)
  # ============================================
  # stdout {
  #   codec => rubydebug
  # }
}
